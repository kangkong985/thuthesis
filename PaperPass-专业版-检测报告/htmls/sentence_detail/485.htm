<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN""http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>PaperPass 最权威论文抄袭检测系统</title>
<style type="text/css">
<!--
user_icon {
color: #FFFFFF;
}
body,td,th {
font-family: "微软雅黑";
font-size: 13px;
}
h1,h2,h3,h4,h5,h6 {
font-family: "宋体";
}
demo_padding {
line-height: 30px;
}
html
{
overflow-x:hidden;
overflow-y:scroll;
}
.liebiao {
border-bottom-width: 1px;
border-bottom-style: dashed;
border-bottom-color: #CCCCCC;
height: 0px;
margin-top:10px;
margin-bottom:10px;
float: left;
width: 90%;
}
.liebiao ul {
list-style-type: none;
display: block;
margin: 0px;
clear: none;
}
.zhengwen {
padding-right: 15px;
padding-left: 0px;
margin-bottom:10px;
font-size: 13px;
line-height: 20px;
color: #666666;
}
.zhengwencenter {
padding-right: 15px;
padding-left: 0px;
margin-bottom:10px;
font-size: 13px;
line-height: 20px;
color: #666666;
text-align:center
}
.neikuang {
background-color: #EBEBEB;
border: 1px dashed #999999;
padding-right: 10px;
padding-left: 10px;
}
.shubu{
float: left;
height: 15px;
width: 15px;
background-color: #FFFFFF;
border: 1px solid #999999;
text-align: center;
vertical-align: middle;
display: block;
font-size: 13px;
}
.kuang {
border: 1px solid #999999;
}
.red{color:#FF0000}
.orange{color:#FF6600}
.green{color:#008000}

a:hover {color:#000000}
a:active {color:#000000}

a{TEXT-DECORATION:none}

-->
</style>
</head>
<body>
<div class="zhengwen">综合&nbsp;&nbsp;|&nbsp;&nbsp;<a href="485_local.htm">本地库</a>&nbsp;&nbsp;|&nbsp;&nbsp;<a href="485_net.htm">互联网</a><br /></div>
<div class="zhengwen">
语句：<span class='orange' > M表示 I帧和其后第一个 P帧之间(或者两个连续 P帧之间)的距离。</span><br><br>
<div style="display:block;">该句相似度：<span class='orange' >46</span>%<a href='#xiugaijianyi' style='padding-left:30px;'>查看该句修改建议</a><b>（轻度相似，请酌情修改）</b><br><br></div>
在本地库和互联网共找出相似内容：4个
</div>

<table width="100%" cellspacing="3" style="margin-bottom:15px;border: 1px solid #C0C0C0" bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF" cellpadding="3">
<tr>
<td align="right" width="100%">
<div class="shubu">1</div>
<font color="#666666">相似度：</font><span class='orange' >46</a><font color="#666">%</font>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">您的句子（灰色背景是与相似句子重合的部分）：</font><br>
<span class='orange' >M表示I<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span>其后第一个P<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">之间</span>(或者两个连续P<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">之间</span>)<span style="background:#cbcbcb">的</span>距离。</span><br>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子：</font><br>
<span class="green">)<span style="background:#cbcbcb">帧</span>。)<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span>这个)<span style="background:#cbcbcb">帧</span>之前<span style="background:#cbcbcb">的</span>*<span style="background:#cbcbcb">帧</span>、)<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">之间</span><span style="background:#cbcbcb">的</span>!<span style="background:#cbcbcb">帧</span>与</span>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子原文片段：</font><br>
……可以考虑思量，因为与这个*帧无关，这个*帧和它随后的)帧之间的!帧也不考虑思量，因此它们与镜头转换检测无关。45(5.镜头转换发生在<span class='green'>)帧。)帧和这个)帧之前的*帧、)帧之间的!帧与</span>前面讨论会商一样，不同的是)帧有前向参考。因为这个)帧是镜头转换帧……
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">来源(学术期刊)：</font><br>
<b>篇名：</b>《一种快速压缩视频数据的镜头转换检测》<br><b>作者：</b>易运池<br><b>作者单位：</b>北京农业职业学院清河分院,北京,100000<br><b>参考文献：</b>4篇<br><b>页码：</b>P62—P64<br><b>页数：</b>3页<br><b>分类号：</b>O436<br><b>机标分类号：</b>TP3 TP2<br><b>期刊名称：</b>《内蒙古科技与经济》<br><b>出版时间：</b>2006年7期<br><b>ISSN：</b>1007-6921<br><b>关键词：</b>镜头转换检测 内部类型 前向类型 后向类型 双向类型<br><b>摘要：</b>对于视频索引的建立来说,视频分割是一项基本的工作.一般认为视频的基本单元是镜头,这篇文章提出了一种新的检测镜头转换的算法,它基于MPEG压缩视频数据的处理. 这种算法利用了隐含在压缩数据中的信息,即各帧所含信息的参考比例确定帧与帧的相似性 ,如果一帧和它相邻的帧相似程度低,镜头转换就被检测到了,考虑到两帧之间视频内容的动态变化,设计了一个变化的函数来提高镜头变化检测的准确性,实验结果证明这种算法是完美的.
</td>
</tr>
</table>


<table width="100%" cellspacing="3" style="margin-bottom:15px;border: 1px solid #C0C0C0" bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF" cellpadding="3">
<tr>
<td align="right" width="100%">
<div class="shubu">2</div>
<font color="#666666">相似度：</font><span class='orange' >44</a><font color="#666">%</font>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">您的句子（灰色背景是与相似句子重合的部分）：</font><br>
<span class='orange' >M表示<span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span>其后第一个<span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span>之间(或者两个连续<span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span>之间)<span style="background:#cbcbcb">的</span>距离。</span><br>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子：</font><br>
<span class="green"><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">的</span><span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span><span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">的</span>重建<span style="background:#cbcbcb">帧</span>对应，即每个<span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span><span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">的</span>重建<span style="background:#cbcbcb">帧</span></span>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子原文片段：</font><br>
……．3合成参考帧的使用方法AVS传统的视频编解码方法可用2个参考帧进行预测，在利用SR帧的视频编码过程中，SR帧与传统视频编解码算法用作参考<span class='green'>帧的I帧和P帧的重建帧对应，即每个I帧和P帧的重建帧</span>都可以有对应的SR帧。SR帧可以作为附加的一帧参考帧，即SR帧可以……
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">来源(学位论文)：</font><br>
<b>篇名：</b>《基于合成参考帧的视频编码技术研究》<br><b>作者：</b>张玉洁<br><b>分类号：</b>TN919.81<br><b>学科专业：</b>信息与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>唐慧明<br><b>学位授予单位：</b>浙江大学<br><b>学位年度：</b>2008<br><b>关键词：</b>视频编码 视频压缩 合成参考帧 运动矢量 编码性能
</td>
</tr>
</table>


<table width="100%" cellspacing="3" style="margin-bottom:15px;border: 1px solid #C0C0C0" bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF" cellpadding="3">
<tr>
<td align="right" width="100%">
<div class="shubu">3</div>
<font color="#666666">相似度：</font><span class='orange' >42</a><font color="#666">%</font>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">您的句子（灰色背景是与相似句子重合的部分）：</font><br>
<span class='orange' >M表示<span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span>其后<span style="background:#cbcbcb">第</span>一个P<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">之间</span>(或者两个连续P<span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">之间</span>)<span style="background:#cbcbcb">的</span>距离。</span><br>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子：</font><br>
<span class="green"><span style="background:#cbcbcb">第</span><span style="background:#cbcbcb">i</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span><span style="background:#cbcbcb">第</span><span style="background:#cbcbcb">i</span>+1、<span style="background:#cbcbcb">第</span><span style="background:#cbcbcb">i</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span><span style="background:#cbcbcb">第</span><span style="background:#cbcbcb">i</span>+2…<span style="background:#cbcbcb">之间</span><span style="background:#cbcbcb">的</span><span style="background:#cbcbcb">帧</span>问</span>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子原文片段：</font><br>
……镜头边界检测算法·21·来计算该起始帧与后续的各个视频帧之间的帧间差异值。如图3(b)所示，第i帧为渐变起始帧，分别计算<span class='green'>第i帧和第i+1、第i帧和第i+2…之间的帧问</span>差异值。当某个帧对应的帧间差异值超出高阈值TH时，则认为该帧为……
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">来源(学术期刊)：</font><br>
<b>篇名：</b>《基于因果的自适应双阈值镜头边界检测算法》<br><b>作者：</b>孙少卿 卓力 赵士伟 张菁<br><b>作者单位：</b>北京工业大学,信号与信息处理研究室,北京,100124<br><b>参考文献：</b>10篇<br><b>被引次数：</b>2次（统计时间：2015年8月）<br><b>页码：</b>P19—P23<br><b>页数：</b>5页<br><b>分类号：</b>TP391<br><b>机标分类号：</b>TP3 TP2<br><b>基金项目：</b>国家自然科学基金(60772069);国家高技术研究发展计划(863计划)(2009AA12Z111)<br><b>期刊名称：</b>《测控技术》<br><b>出版时间：</b>2009年5期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-8829<br><b>关键词：</b>镜头边界检测 自适应双阈值 因果法 帧间差异值<br><b>摘要：</b>将因果检测法与双阈值法相结合,提出了一种基于因果的自适应双阈值镜头边界检测算法.首先,利用相邻两帧之间的帧间差异值对突变和渐变进行预检;然后,加入渐变检测容忍度、边缘和非相邻帧间差异值等信息,对初检结果进行复检,排除闪光灯、剧烈物体运动、淡入、淡出以及溶解等造成的误检和漏检,以提高整体检测效果.实验结果表明,与传统的双阈值镜头检测方法相比,本方法可获得更好的检测性能.
</td>
</tr>
</table>


<table width="100%" cellspacing="3" style="margin-bottom:15px;border: 1px solid #C0C0C0" bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF" cellpadding="3">
<tr>
<td align="right" width="100%">
<div class="shubu">4</div>
<font color="#666666">相似度：</font><span class='orange' >42</a><font color="#666">%</font>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">您的句子（灰色背景是与相似句子重合的部分）：</font><br>
<span class='orange' >M表示<span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span><span style="background:#cbcbcb">和</span>其后<span style="background:#cbcbcb">第</span>一个<span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span>之间(或者两个连续<span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span>之间)的距离。</span><br>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子：</font><br>
<span class="green"><span style="background:#cbcbcb">帧</span>(<span style="background:#cbcbcb">I</span><span style="background:#cbcbcb">帧</span>)<span style="background:#cbcbcb">和</span><span style="background:#cbcbcb">第</span>4<span style="background:#cbcbcb">帧</span>(<span style="background:#cbcbcb">P</span><span style="background:#cbcbcb">帧</span>)为参考<span style="background:#cbcbcb">帧</span>。B<span style="background:#cbcbcb">帧</span>则是根据</span>
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">相似句子原文片段：</font><br>
……解码。P帧和B帧为帧间编码。P帧以I帧或前一个P帧为参考帧而形成预测编码帧，如图1中，第8帧是以第l<span class='green'>帧(I帧)和第4帧(P帧)为参考帧。B帧则是根据</span>一定判据自适应地选择其前或其后的I帧或P帧进行预测，如图’1……
</td>
</tr>
<tr>
<td align="left" width="100%">
<font color="#666666">来源(学术期刊)：</font><br>
<b>篇名：</b>《视频镜头分割技术综述》<br><b>作者：</b>孙利涛 杨雷<br><b>作者单位：</b>山东轻工业学院,信息科学与技术学院,山东,济南,250353；山东畜牧兽医职业学院,山东,潍坊,260161<br><b>参考文献：</b>7篇<br><b>被引次数：</b>3次（统计时间：2015年8月）<br><b>页码：</b>P36—P39<br><b>页数：</b>4页<br><b>分类号：</b>TP391<br><b>机标分类号：</b>TP3 TN9<br><b>期刊名称：</b>《山东轻工业学院学报（自然科学版）》<br><b>出版时间：</b>2007年1期<br><b>ISSN：</b>1004-4280<br><b>关键词：</b>视频分割 镜头检测 视频检索<br><b>摘要：</b>视频序列的镜头分割亦称镜头变化检测是视频检索中的关键技术之一.镜头变化是指视频序列中场景内容的变化.随着数字视频的飞速增长,对视频内容快速而有效的检索技术变得越来越重要.本文概述了基于内容的视频分割技术.主要包括非压缩域和压缩域两个主要方面的镜头变换检测方法.
</td>
</tr>
</table>




<div style="display:block;">
<table id="xiugaijianyi" width="100%" cellpadding="3" cellspacing="3" style="margin-bottom:15px;margin-top:15px;border: 1px solid #C0C0C0;"
bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF">
<tbody>
<tr>
<td width="100%">
<div class="green" style="font-size:17px;padding-left:5px;">
该句修改建议（轻度相似，请酌情修改）
</div>
</td>
</tr>
<tr>
<td>
<div class="shubu">
1
</div>
<span style="  padding-left:10px;font-size:15px;">
原句与相似内容重合部分（重点修改标红部分）：
</span>
</td>
</tr>
<tr>
<td>
<font class="green">
M表示I帧和其后第一个P帧<span class="red">之间</span>(或者两个连续P帧<span class="red">之间</span>)的距离。
</font>
</td>
</tr>
<tr>
<td>
<div class="shubu">
2
</div>
<span style="  padding-left:10px;font-size:15px;">
同义词：
</span>
</td>
</tr>
<tr>
<td width="100%" align="left">
<span class="red">表示：</span><span class="green">暗示 表现 默示 </span><br/> <span class="red">其后：</span><span class="green">厥后 后来 </span><br/> <span class="red">连续：</span><span class="green">持续 接连 继续 </span><br/>
</td>
</tr>
</tbody>
</table>
</div>

<div style="display:block;">
<a href="#">回到顶部</a>
</div>

<div style="margin-bottom:100px"></div>
<div class="zhengwencenter">
<p>
检测报告由<a href="http://www.paperpass.com/" target="_blank">PaperPass</a>文献相似度检测系统生成
</p>
<p>
Copyright © 2007-2016 PaperPass
</p>
</div>
<div style="margin-bottom:700px"></div>
</body>
</html>
